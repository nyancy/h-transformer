{"cells":[{"cell_type":"markdown","metadata":{"id":"VdTCf3vHc9eQ"},"source":["# Imports and Colab Mount"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WA0xM236cFzP","executionInfo":{"status":"ok","timestamp":1649133247832,"user_tz":-540,"elapsed":5695,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}}},"outputs":[],"source":["import datetime\n","import seaborn as sn\n","import pandas as pd\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import scipy.stats as stats\n","import glob\n","from math import sqrt\n","from tqdm import tqdm\n","\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","import keras\n","from tensorflow.keras.optimizers import Adam\n","from keras.layers import Dense, LSTM, LeakyReLU, Dropout, GRU, SimpleRNN, Input, LSTM, Dense, Bidirectional, Concatenate, Reshape, Lambda, Bidirectional\n","from keras.models import Model, Sequential\n","from keras import backend as K\n","from tensorflow.keras import layers\n","from keras.callbacks import Callback, ReduceLROnPlateau, EarlyStopping\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","\n","from numpy.random import seed\n","#from tensorflow import set_random_seed\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LIhGU4HNc5uw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649133268128,"user_tz":-540,"elapsed":20301,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"70c44947-117d-408c-bffa-a59ca4fc2fb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"yz0e7vrtdDWe"},"source":["# Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"NNIJ9EXxdP5f","executionInfo":{"status":"ok","timestamp":1649133271050,"user_tz":-540,"elapsed":1360,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}}},"outputs":[],"source":["train_h = pd.read_csv(\"/content/drive/MyDrive/Datasets/solar_train.csv\", index_col=0, parse_dates=True)\n","valid_h = pd.read_csv(\"/content/drive/MyDrive/Datasets/solar_valid.csv\", index_col=0, parse_dates=True)\n","test_h = pd.read_csv(\"/content/drive/MyDrive/Datasets/solar_test.csv\", index_col=0, parse_dates=True)\n","hourly = pd.read_csv(\"/content/drive/MyDrive/Datasets/solar_all.csv\", index_col=0, parse_dates=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"twTRqY3aeIX-","executionInfo":{"status":"ok","timestamp":1649133271051,"user_tz":-540,"elapsed":6,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}}},"outputs":[],"source":["def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n","\tn_vars = 1 if type(data) is list else data.shape[1]\n","\tdf = pd.DataFrame(data)\n","\tcols, names = list(), list()\n","\t# input sequence (t-n, ... t-1)\n","\tfor i in range(n_in, 0, -1):\n","\t\tcols.append(df.shift(i))\n","\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n","\t# forecast sequence (t, t+1, ... t+n)\n","\tfor i in range(0, n_out):\n","\t\tcols.append(df.shift(-i))\n","\t\tif i == 0:\n","\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n","\t\telse:\n","\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n","\t# put it all together\n","\tagg = pd.concat(cols, axis=1)\n","\tagg.columns = names\n","\t# drop rows with NaN values\n","\tif dropnan:\n","\t\tagg.dropna(inplace=True)\n","\treturn agg"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6Ghi6ux7eSHe","executionInfo":{"status":"ok","timestamp":1649133271051,"user_tz":-540,"elapsed":5,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}}},"outputs":[],"source":["def make_data(data, timestep, resid_check=False):\n","  values = data.values\n","  values = values.astype('float32')\n","  #scaler = MinMaxScaler(feature_range=(0, 1))\n","  #scaled = scaler.fit_transform(values)\n","  \n","  timestep = timestep\n","  n_features = 39\n","  n_obs = timestep * n_features\n","  reframed = series_to_supervised(values, timestep, 1)\n","  reframed = reframed.iloc[: , :-38]\n","\n","  values = reframed.values\n","  indice1 = train_h.shape[0]\n","  indice2 = valid_h.shape[0]\n","\n","  train = values[:indice1, :]\n","  valid = values[indice1:indice1+indice2, :]\n","  test = values[indice1+indice2:, :]\n","\n","  train_X, train_y = train[:, :-1], train[:, -1]\n","  valid_X, valid_y = valid[:, :-1], valid[:, -1]\n","  test_X, test_y = test[:, :-1], test[:, -1]\n","\n","  if (resid_check==True):\n","    train_y = resid_train.values[:2184]\n","    valid_y = resid_train.values[2184:]\n","\n","  scaler = MinMaxScaler(feature_range=(0, 1)).fit(train_X)\n","  train_X = scaler.transform(train_X)\n","  valid_X = scaler.transform(valid_X)\n","  test_X = scaler.transform(test_X)\n","\n","  scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(train_y.reshape(-1,1))\n","  train_y = scaler_y.transform(train_y.reshape(-1,1))\n","  valid_y = scaler_y.transform(valid_y.reshape(-1,1))\n","  test_y = scaler_y.transform(test_y.reshape(-1,1))\n","\n","  train_X = train_X.reshape((train_X.shape[0], timestep, n_features))\n","  valid_X = valid_X.reshape((valid_X.shape[0], timestep, n_features))\n","  test_X = test_X.reshape((test_X.shape[0], timestep, n_features))\n","  return train_X, train_y, valid_X, valid_y, test_X, test_y"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZGNGDxk7f3lP","executionInfo":{"status":"ok","timestamp":1649133271052,"user_tz":-540,"elapsed":6,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}}},"outputs":[],"source":["def make_data2(data, timestep, resid_check=False):\n","  values = data.values\n","  values = values.astype('float32')\n","  #scaler = MinMaxScaler(feature_range=(0, 1))\n","  #scaled = scaler.fit_transform(values)\n","  \n","  timestep = timestep\n","  n_features = 39\n","  n_obs = timestep * n_features\n","  reframed = series_to_supervised(values, timestep, 1)\n","  reframed = reframed.iloc[: , :-38]\n","\n","  values = reframed.values\n","  indice1 = train_h.shape[0]\n","  indice2 = valid_h.shape[0]\n","\n","  train = values[:indice1, :]\n","  valid = values[indice1:indice1+indice2, :]\n","  test = values[indice1+indice2:, :]\n","\n","  train_X, train_y = train[:, :-1], train[:, -1]\n","  valid_X, valid_y = valid[:, :-1], valid[:, -1]\n","  test_X, test_y = test[:, :-1], test[:, -1]\n","\n","  if (resid_check==True):\n","    train_y = resid_train.values[:2184]\n","    valid_y = resid_train.values[2184:]\n","\n","  scaler = MinMaxScaler(feature_range=(0, 1)).fit(train_X)\n","  train_X = scaler.transform(train_X)\n","  valid_X = scaler.transform(valid_X)\n","  test_X = scaler.transform(test_X)\n","\n","  scaler_y = MinMaxScaler(feature_range=(0, 1)).fit(train_y.reshape(-1,1))\n","  train_y = scaler_y.transform(train_y.reshape(-1,1))\n","  valid_y = scaler_y.transform(valid_y.reshape(-1,1))\n","  test_y = scaler_y.transform(test_y.reshape(-1,1))\n","\n","  train_X = train_X.reshape((train_X.shape[0], timestep, n_features))\n","  valid_X = valid_X.reshape((valid_X.shape[0], timestep, n_features))\n","  test_X = test_X.reshape((test_X.shape[0], timestep, n_features))\n","  return train_X, train_y, valid_X, valid_y, test_X, test_y, scaler, scaler_y"]},{"cell_type":"markdown","metadata":{"id":"0_GIYJM3gtZ1"},"source":["# WanDB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"He_mrhkVgvlv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648626725607,"user_tz":-540,"elapsed":25056,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"580b939e-828b-415a-ffce-49326f5a4106"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n","\u001b[K     |████████████████████████████████| 144 kB 60.6 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 29.7 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.2 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}],"source":["!pip install wandb -qq\n","import wandb\n","from wandb.keras import WandbCallback\n","!wandb login"]},{"cell_type":"markdown","metadata":{"id":"Wckz4IzLgVFo"},"source":["# Test"]},{"cell_type":"markdown","metadata":{"id":"15vG2PmdmOKl"},"source":["# RNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qIM46d7mmspt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648627182282,"user_tz":-540,"elapsed":425137,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"28af867e-b4e2-4801-fda0-acf00cef8a8f"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1/10 [00:49<07:29, 49.95s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [01:33<06:07, 46.00s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [02:16<05:12, 44.68s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [03:14<04:59, 49.98s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [03:58<03:58, 47.73s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [04:37<03:00, 45.05s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [05:20<02:12, 44.14s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [06:02<01:27, 43.68s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [06:31<00:39, 39.00s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [07:04<00:00, 42.46s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","RNN LIST OF RMSE: [1068.5556840895097, 1159.240268451713, 1379.9390385085858, 1176.7722273235377, 1161.6255851176832, 1528.136610385341, 1112.091891437034, 1141.5379976154977, 1790.3627425748114, 1128.1197853065073]\n","RNN RMSE:  1264.6381830810221\n","RNN LIST OF MAE: [865.2617, 861.32086, 1092.1304, 928.2128, 881.0841, 1299.1615, 821.06195, 875.2505, 1478.8761, 841.22095]\n","RNN MAE:  994.3580871582031\n","RNN LIST OF MAPE: [0.3519668, 0.2943436, 0.34910986, 0.32278258, 0.30088556, 0.45316443, 0.2896887, 0.31686652, 0.38811088, 0.29890344]\n","RNN MAPE:  0.33658223450183866\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rmse_list = []\n","mae_list = []\n","mape_list = []\n","\n","timestep=6\n","layers=2\n","num_units=256\n","dropout=0\n","lr=0.01\n","batch_size=128\n","\n","for z in tqdm(range(10)):\n","  train_X, train_y, valid_X, valid_y, test_X, test_y, scaler, scaler_y = make_data2(hourly, 6, resid_check=False)\n","  model = Sequential()\n","\n","  if layers > 1:\n","    model.add(SimpleRNN(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout, return_sequences=True))\n","\n","    for i in range(layers-2):\n","      model.add(SimpleRNN(units = num_units, dropout=dropout, return_sequences=True))\n","\n","    model.add(SimpleRNN(units = num_units, dropout=dropout))\n","\n","  else:\n","    model.add(SimpleRNN(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout))\n","\n","  model.add(Dense(units = 1))\n","\n","  model.compile(\n","    loss=\"mse\",\n","    optimizer=Adam(learning_rate=lr)\n","  )\n","\n","  model.fit(train_X, train_y, batch_size=batch_size,\n","          epochs=200, verbose=0, shuffle=False,\n","          validation_data=(valid_X, valid_y),\n","          callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n","  \n","  # make a prediction\n","  yhat = model.predict(test_X)\n","  yhat_inv = scaler_y.inverse_transform(yhat)\n","  #resid_sum = (yhat_inv+resid_test.values[3:])\n","\n","  rmse_list.append(sqrt(mean_squared_error(yhat_inv, scaler_y.inverse_transform(test_y))))\n","  mae_list.append(mean_absolute_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  mape_list.append(mean_absolute_percentage_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  print()\n","print(f\"RNN LIST OF RMSE: {rmse_list}\")\n","print(f'RNN RMSE:  {sum(rmse_list)/len(rmse_list)}')\n","\n","print(f\"RNN LIST OF MAE: {mae_list}\")\n","print(f'RNN MAE:  {sum(mae_list)/len(mae_list)}')\n","\n","print(f\"RNN LIST OF MAPE: {mape_list}\")\n","print(f'RNN MAPE:  {sum(mape_list)/len(mape_list)}')"]},{"cell_type":"markdown","metadata":{"id":"Op-rtqjIhCZO"},"source":["# LSTM"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"uutPNh2svbbm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649135076702,"user_tz":-540,"elapsed":172359,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"2a84e45b-a5d0-4f63-e5f4-22c42261dfa1"},"outputs":[{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1/10 [00:15<02:20, 15.64s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [00:41<02:51, 21.42s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [00:56<02:12, 18.89s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [01:11<01:42, 17.08s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [01:27<01:22, 16.60s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [01:52<01:19, 19.77s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [02:08<00:54, 18.27s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [02:22<00:33, 17.00s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [02:36<00:15, 15.96s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [02:51<00:00, 17.19s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","LSTM LIST OF RMSE: [963.6882600198054, 929.7355470777699, 928.8288997441887, 1008.1366164860792, 973.3494362252438, 891.9060698862858, 886.3810904458646, 1015.9572456555443, 1006.7303511864535, 963.3463486721689]\n","LSTM RMSE:  956.8059865399404\n","LSTM LIST OF MAE: [714.864, 660.08813, 712.111, 757.5335, 713.8564, 642.4371, 636.3678, 730.4109, 771.0856, 714.8614]\n","LSTM MAE:  705.3615783691406\n","LSTM LIST OF MAPE: [0.27761814, 2.8527899, 0.32956073, 0.2855545, 0.2899234, 0.32398516, 0.30619875, 0.38147333, 0.28862876, 0.28174567]\n","LSTM MAPE:  0.5617478311061859\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rmse_list = []\n","mae_list = []\n","mape_list = []\n","\n","timestep=6\n","layers=2\n","num_units=64\n","dropout=0.1\n","lr=0.01\n","batch_size=128\n","\n","for z in tqdm(range(10)):\n","  train_X, train_y, valid_X, valid_y, test_X, test_y, scaler, scaler_y = make_data2(hourly, timestep, resid_check=False)\n","  model = Sequential()\n","\n","  if layers > 1:\n","    model.add(LSTM(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout, return_sequences=True))\n","\n","    for i in range(layers-2):\n","      model.add(LSTM(units = num_units, dropout=dropout, return_sequences=True))\n","\n","    model.add(LSTM(units = num_units, dropout=dropout))\n","\n","  else:\n","    model.add(LSTM(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout))\n","\n","  model.add(Dense(units = 1))\n","\n","  model.compile(\n","    loss=\"mse\",\n","    optimizer=Adam(learning_rate=lr)\n","  )\n","\n","  model.fit(train_X, train_y, batch_size=batch_size,\n","          epochs=200, verbose=0, shuffle=False,\n","          validation_data=(valid_X, valid_y),\n","          callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n","  \n","  # make a prediction\n","  yhat = model.predict(test_X)\n","  yhat_inv = scaler_y.inverse_transform(yhat)\n","  #resid_sum = (yhat_inv+resid_test.values[3:])\n","\n","  rmse_list.append(sqrt(mean_squared_error(yhat_inv, scaler_y.inverse_transform(test_y))))\n","  mae_list.append(mean_absolute_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  mape_list.append(mean_absolute_percentage_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  print()\n","print(f\"LSTM LIST OF RMSE: {rmse_list}\")\n","print(f'LSTM RMSE:  {sum(rmse_list)/len(rmse_list)}')\n","\n","print(f\"LSTM LIST OF MAE: {mae_list}\")\n","print(f'LSTM MAE:  {sum(mae_list)/len(mae_list)}')\n","\n","print(f\"LSTM LIST OF MAPE: {mape_list}\")\n","print(f'LSTM MAPE:  {sum(mape_list)/len(mape_list)}')"]},{"cell_type":"code","source":["rmse_list = []\n","mae_list = []\n","mape_list = []\n","\n","timestep=6\n","layers=2\n","num_units=64\n","dropout=0.1\n","lr=0.01\n","batch_size=128\n","\n","for z in tqdm(range(10)):\n","  train_X, train_y, valid_X, valid_y, test_X, test_y, scaler, scaler_y = make_data2(hourly, timestep, resid_check=False)\n","  model = Sequential()\n","\n","  if layers > 1:\n","    model.add(LSTM(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout, return_sequences=True))\n","\n","    for i in range(layers-2):\n","      model.add(LSTM(units = num_units, dropout=dropout, return_sequences=True))\n","\n","    model.add(LSTM(units = num_units, dropout=dropout))\n","\n","  else:\n","    model.add(LSTM(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout))\n","\n","  model.add(Dense(units = 1))\n","\n","  model.compile(\n","    loss=\"mse\",\n","    optimizer=Adam(learning_rate=lr)\n","  )\n","\n","  model.fit(train_X, train_y, batch_size=batch_size,\n","          epochs=200, verbose=0, shuffle=False,\n","          validation_data=(valid_X, valid_y),\n","          callbacks=[EarlyStopping(patience=20, restore_best_weights=True), ReduceLROnPlateau(monitor='val_loss',patience=5, min_lr=1e-6)])\n","  \n","  # make a prediction\n","  yhat = model.predict(test_X)\n","  yhat_inv = scaler_y.inverse_transform(yhat)\n","  #resid_sum = (yhat_inv+resid_test.values[3:])\n","\n","  rmse_list.append(sqrt(mean_squared_error(yhat_inv, scaler_y.inverse_transform(test_y))))\n","  mae_list.append(mean_absolute_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  mape_list.append(mean_absolute_percentage_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  print()\n","print(f\"LSTM LIST OF RMSE: {rmse_list}\")\n","print(f'LSTM RMSE:  {sum(rmse_list)/len(rmse_list)}')\n","\n","print(f\"LSTM LIST OF MAE: {mae_list}\")\n","print(f'LSTM MAE:  {sum(mae_list)/len(mae_list)}')\n","\n","print(f\"LSTM LIST OF MAPE: {mape_list}\")\n","print(f'LSTM MAPE:  {sum(mape_list)/len(mape_list)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z07h9Wms_oJa","executionInfo":{"status":"ok","timestamp":1649135440152,"user_tz":-540,"elapsed":243310,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"c09ae4cc-17a0-41c4-f1ca-8aeef714a019"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1/10 [00:17<02:40, 17.81s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 2/10 [00:43<03:01, 22.74s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 3/10 [01:09<02:49, 24.19s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 4/10 [01:35<02:28, 24.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 5/10 [02:01<02:06, 25.33s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 6/10 [02:27<01:41, 25.36s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 7/10 [02:53<01:16, 25.56s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 8/10 [03:19<00:51, 25.69s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 9/10 [03:36<00:23, 23.11s/it]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [04:02<00:00, 24.28s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","LSTM LIST OF RMSE: [976.9073011294367, 968.8100949102461, 1059.009855950359, 985.4152360807093, 986.2787068065497, 982.8246600996538, 957.82458597595, 1008.2015857456286, 922.5306905463905, 1012.7413601211318]\n","LSTM RMSE:  986.0544077366055\n","LSTM LIST OF MAE: [723.0525, 693.693, 786.77966, 707.9397, 707.80066, 715.1701, 688.6474, 748.45184, 656.5426, 771.4806]\n","LSTM MAE:  719.9558044433594\n","LSTM LIST OF MAPE: [0.30149546, 0.28810877, 0.28271756, 0.31732655, 0.28096387, 0.28739175, 0.32207233, 0.281074, 0.35629702, 0.3013806]\n","LSTM MAPE:  0.3018827885389328\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"nZYNeaW_mD9c"},"source":["# GRU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3k5K35Dvj2b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648629561060,"user_tz":-540,"elapsed":2208120,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"785fad2b-f214-4650-ae93-a0e81f82252f"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [36:47<00:00, 220.78s/it]"]},{"output_type":"stream","name":"stdout","text":["GRU LIST OF RMSE: [1047.4952267194346, 960.2672154145429, 1004.9950248633074, 1017.5268423977817, 1005.5185540307051, 923.7623476847278, 1195.4631947492153, 997.4431688071255, 971.634705020359, 955.6800262117023]\n","GRU RMSE:  1007.9786305898903\n","GRU LIST OF MAE: [827.2577, 733.55176, 804.21875, 722.3083, 713.299, 645.6095, 960.50946, 761.9838, 706.05237, 643.83325]\n","GRU MAE:  751.8623901367188\n","GRU LIST OF MAPE: [0.30466995, 0.29843897, 0.37575185, 0.2929131, 0.24875705, 0.43719256, 0.33111233, 0.3117522, 0.29438516, 0.33002964]\n","GRU MAPE:  0.3225002810359001\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rmse_list = []\n","mae_list = []\n","mape_list = []\n","\n","timestep=12\n","layers=8\n","num_units=64\n","dropout=0.1\n","lr=0.01\n","batch_size=32\n","\n","for z in tqdm(range(10)):\n","  train_X, train_y, valid_X, valid_y, test_X, test_y, scaler, scaler_y = make_data2(hourly, timestep, resid_check=False)\n","  model = Sequential()\n","\n","  if layers > 1:\n","    model.add(GRU(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout, return_sequences=True))\n","\n","    for i in range(layers-2):\n","      model.add(GRU(units = num_units, dropout=dropout, return_sequences=True))\n","\n","    model.add(GRU(units = num_units, dropout=dropout))\n","\n","  else:\n","    model.add(GRU(units = num_units, input_shape=(train_X.shape[1], train_X.shape[2]), dropout=dropout))\n","\n","  model.add(Dense(units = 1))\n","\n","  model.compile(\n","    loss=\"mse\",\n","    optimizer=Adam(learning_rate=lr)\n","  )\n","\n","  model.fit(train_X, train_y, batch_size=batch_size,\n","          epochs=200, verbose=0, shuffle=False,\n","          validation_data=(valid_X, valid_y),\n","          callbacks=[EarlyStopping(patience=10, restore_best_weights=True)])\n","  \n","  # make a prediction\n","  yhat = model.predict(test_X)\n","  yhat_inv = scaler_y.inverse_transform(yhat)\n","  #resid_sum = (yhat_inv+resid_test.values[3:])\n","\n","  rmse_list.append(sqrt(mean_squared_error(yhat_inv, scaler_y.inverse_transform(test_y))))\n","  mae_list.append(mean_absolute_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  mape_list.append(mean_absolute_percentage_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","print(f\"GRU LIST OF RMSE: {rmse_list}\")\n","print(f'GRU RMSE:  {sum(rmse_list)/len(rmse_list)}')\n","\n","print(f\"GRU LIST OF MAE: {mae_list}\")\n","print(f'GRU MAE:  {sum(mae_list)/len(mae_list)}')\n","\n","print(f\"GRU LIST OF MAPE: {mape_list}\")\n","print(f'GRU MAPE:  {sum(mape_list)/len(mape_list)}')"]},{"cell_type":"markdown","metadata":{"id":"TE8Ow8HAsDUs"},"source":["# Transformer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eLKekJI7sK17"},"outputs":[],"source":["from tensorflow.keras import layers\n","\n","class TransformerBlock(layers.Layer):\n","    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate = 0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.att = layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)\n","        self.ffn = keras.Sequential( [layers.Dense(ff_dim, activation = \"gelu\"), layers.Dense(feat_dim),] )\n","        self.layernorm1 = layers.BatchNormalization()\n","        self.layernorm2 = layers.BatchNormalization()\n","        self.dropout1 = layers.Dropout(rate)\n","        self.dropout2 = layers.Dropout(rate)\n","        self.embed_dim = embed_dim\n","        self.feat_dim = feat_dim\n","        self.num_heads = num_heads\n","        self.ff_dim = ff_dim\n","        self.rate = rate\n","\n","    def call(self, inputs, training):\n","        attn_output = self.att(inputs, inputs)\n","        attn_output = self.dropout1(attn_output, training = training)\n","        out1 = self.layernorm1(inputs + attn_output)\n","        ffn_output = self.ffn(out1)\n","        ffn_output = self.dropout2(ffn_output, training = training)\n","        return self.layernorm2(out1 + ffn_output)\n","\n","    def get_config(self):\n","\n","        config = super().get_config()\n","        config.update({\n","            'embed_dim': self.embed_dim,\n","            'feat_dim': self.feat_dim,\n","            'num_heads': self.num_heads,\n","            'ff_dim': self.ff_dim,\n","            'rate': self.rate,\n","        })\n","        return config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZBGJvE12sMkF"},"outputs":[],"source":["class Time2Vec(keras.layers.Layer):\n","    def __init__(self, kernel_size = 1):\n","        super(Time2Vec, self).__init__(trainable = True, name = 'Time2VecLayer')\n","        self.k = kernel_size\n","\n","    def build(self, input_shape):\n","        # trend\n","        self.wb = self.add_weight(name = 'wb', shape = (input_shape[1],), initializer = 'uniform', trainable = True)\n","        self.bb = self.add_weight(name = 'bb', shape = (input_shape[1],), initializer = 'uniform', trainable = True)\n","        # periodic\n","        self.wa = self.add_weight(name = 'wa', shape = (1, input_shape[1], self.k), initializer = 'uniform', trainable = True)\n","        self.ba = self.add_weight(name = 'ba', shape = (1, input_shape[1], self.k), initializer = 'uniform', trainable = True)\n","        super(Time2Vec, self).build(input_shape)\n","\n","    def call(self, inputs, **kwargs):\n","        bias = self.wb * inputs + self.bb\n","        dp = K.dot(inputs, self.wa) + self.ba\n","        wgts = K.sin(dp) # or K.cos(.)\n","        ret = K.concatenate([K.expand_dims(bias, -1), wgts], -1)\n","        ret = K.reshape(ret, (-1, inputs.shape[1] * (self.k + 1)))\n","        return ret\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], input_shape[1] * (self.k + 1))\n","\n","    def get_config(self):\n","\n","        config = super().get_config()\n","        config.update({\n","            'kernel_size': self.k,\n","        })\n","        return config"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ej51TZCsOCO"},"outputs":[],"source":["EPOCHS = 50\n","N_HEADS = 8\n","N_FOLDS = 10\n","FF_DIM = 256\n","N_BLOCKS = 6\n","EMBED_DIM = 64\n","BATCH_SIZE = 16\n","WINDOW_SIZE = 65\n","DROPUT_RATE = 0.0\n","TIME_2_VEC_DIM = 3\n","TRAIN_MODEL = True\n","SKIP_CONNECTION_STRENGTH = 0.9"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HbPVz-6SwCUD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648697272661,"user_tz":-540,"elapsed":4389711,"user":{"displayName":"Guilherme Afonso Galindo Padilha","userId":"04417560273321122628"}},"outputId":"ecbc58c8-31f2-4888-b9f2-bb76dffc1190"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [1:13:09<00:00, 438.94s/it]"]},{"output_type":"stream","name":"stdout","text":["Transformer LIST OF RMSE: [1069.345594277173, 1180.647280096812, 1145.9040099414958, 974.9583003903296, 1018.4296121971316, 1091.3377112516546, 1031.2739088137546, 1144.9281636853902, 1080.3077107935499, 1164.1378784319322]\n","Transformer RMSE:  1090.1270169879222\n","Transformer LIST OF MAE: [809.22424, 946.4375, 906.5738, 720.68304, 763.6714, 869.78345, 776.4992, 913.0993, 836.0788, 951.6148]\n","Transformer MAE:  849.366552734375\n","Transformer LIST OF MAPE: [0.62974226, 0.30611587, 0.30105332, 0.27899137, 0.3038196, 0.3025636, 0.5804642, 0.30953628, 0.28656432, 0.31644234]\n","Transformer MAPE:  0.3615293145179749\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["rmse_list = []\n","mae_list = []\n","mape_list = []\n","\n","batch_size=32\n","lr=0.001\n","N_HEADS = 4\n","FF_DIM = 256\n","N_BLOCKS = 2\n","EMBED_DIM = 128\n","DROPUT_RATE = 0.3\n","time2vec_dim = 2\n","timestep = 24\n","\n","for z in tqdm(range(10)):\n","  train_X, train_y, valid_X, valid_y, test_X, test_y, scaler, scaler_y = make_data2(hourly, timestep, resid_check=False)\n","\n","\n","  input_shape = train_X.shape[1:]\n","  inp = Input(input_shape)\n","  x = inp\n","\n","  time_embedding = keras.layers.TimeDistributed(Time2Vec(time2vec_dim - 1))(x)\n","  x = Concatenate(axis = -1)([x, time_embedding])\n","  x = layers.LayerNormalization(epsilon = 1e-6)(x)\n","\n","  for k in range(N_BLOCKS):\n","    x_old = x\n","    transformer_block = TransformerBlock(EMBED_DIM, input_shape[-1] + ( input_shape[-1] * time2vec_dim), N_HEADS, FF_DIM, DROPUT_RATE)\n","    x = transformer_block(x)\n","    x = ((1.0 - SKIP_CONNECTION_STRENGTH) * x) + (SKIP_CONNECTION_STRENGTH * x_old)\n","\n","  x = layers.Flatten()(x)\n","\n","  x = layers.Dense(128, activation = \"relu\")(x)\n","  x = layers.Dropout(DROPUT_RATE)(x)\n","  x = Dense(1, activation = 'linear')(x)\n","\n","  out = x\n","  model = Model(inp, out)\n","\n","  model.compile(\n","    loss=\"mse\",\n","    optimizer=Adam(learning_rate=lr)\n","              )\n","\n","  model.fit(train_X, train_y, batch_size=batch_size,\n","          epochs=200, verbose=0, shuffle=False,\n","          validation_data=(valid_X, valid_y),\n","          callbacks=[EarlyStopping(patience=10, restore_best_weights=True)]\n","          )\n","  \n","  # make a prediction\n","  yhat = model.predict(test_X)\n","  yhat_inv = scaler_y.inverse_transform(yhat)\n","  #resid_sum = (yhat_inv+resid_test.values[3:])\n","\n","  rmse_list.append(sqrt(mean_squared_error(yhat_inv, scaler_y.inverse_transform(test_y))))\n","  mae_list.append(mean_absolute_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","  mape_list.append(mean_absolute_percentage_error(yhat_inv, scaler_y.inverse_transform(test_y)))\n","print(f\"Transformer LIST OF RMSE: {rmse_list}\")\n","print(f'Transformer RMSE:  {sum(rmse_list)/len(rmse_list)}')\n","\n","print(f\"Transformer LIST OF MAE: {mae_list}\")\n","print(f'Transformer MAE:  {sum(mae_list)/len(mae_list)}')\n","\n","print(f\"Transformer LIST OF MAPE: {mape_list}\")\n","print(f'Transformer MAPE:  {sum(mape_list)/len(mape_list)}')"]}],"metadata":{"colab":{"name":"DF1_Simple_Test.ipynb","provenance":[],"authorship_tag":"ABX9TyNvZ/soCtWXpAhcDal2JmdN"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}